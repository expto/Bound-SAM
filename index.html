<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="We first re-caption 30M images with detailed descriptions using a pre-trained Multi-modality Large Language Model (MLLM), and then study the usage of the resulting captions under a contrastive learning framework.">
  <meta name="keywords" content="Language-Image Pre-training, Long Captions">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AesExpert: Towards Multi-modality Foundation Model for Image Aesthetics Perception</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>

<head>
    <meta charset="UTF-8">
    <title>adaptive image</title>
    <style>
        .responsive-image {
            width: 50%; 
            max-width: 600px;
            height: auto;
            display: block;
            margin-left: auto;
            margin-right: auto;
        }
    </style>
</head>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">AesExpert: Towards Multi-modality Foundation Model for Image Aesthetics Perception</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/yipoh/AesExpert">Yipo Huang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/yipoh/AesExpert">Xiangfei Sheng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/yipoh/AesExpert">Zhichao Yang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/yipoh/AesExpert">Quan Yuan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/yipoh/AesExpert">Zhichao Duan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=LXEuY3IAAAAJ">Pengfei Chen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=xMvuFI8AAAAJ&hl=zh-CN">Leida Li</a><sup>*1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=D_S41X4AAAAJ&hl=zh-CN">Weisi Lin</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=11aRt9oAAAAJ&view_op=list_works&sortby=pubdate">Guangming Shi</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Xidian University, China    </span>
            <span class="author-block"><sup>2</sup>Nanyang Technological University, Singapore</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2404.09624"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2404.09624"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/yipoh/AesExpert"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/yipoh/AesExpert"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="subtitle has-text-centered">
    <div class="hero-body">
      <img src='static/images/fig1.jpg' width="1024" height="880",id="teaser-1">
      <h2 class="subtitle has-text-centered">
<!--        <p>-->
<!--          <b>Concept diagrams</b> of generated long caption, image-text retrival, semantic segmentation and image understanding in MLLM.-->
<!--        </p>-->
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            
          The highly abstract nature of image aesthetics perception (IAP) poses significant challenge for current multimodal large language models (MLLMs). 
          The lack of human-annotated multi-modality aesthetic data further exacerbates this dilemma, resulting in MLLMs falling short of aesthetics perception capabilities. 
          To address the above challenge, we first introduce a comprehensively annotated Aesthetic Multi-Modality Instruction Tuning (AesMMIT) dataset, which serves as the footstone for building multi-modality aesthetics foundation models. 
          Specifically, to align MLLMs with human aesthetics perception, we construct a corpus-rich aesthetic critique database with 21,904 diverse-sourced images and 88K human natural language feedbacks, which are collected via progressive questions, ranging from coarse-grained aesthetic grades to fine-grained aesthetic descriptions. 
          To ensure that MLLMs can handle diverse queries, we further prompt GPT to refine the aesthetic critiques and assemble the large-scale aesthetic instruction tuning dataset, <i>i.e.</i> AesMMIT, which consists of 409K multi-typed instructions to activate stronger aesthetic capabilities. 
          Based on the AesMMIT database, we fine-tune the open-sourced general foundation models, achieving multi-modality Aesthetic Expert models, dubbed AesExpert. 
          Extensive experiments demonstrate that the proposed AesExpert models deliver significantly better aesthetic perception performances than the state-of-the-art MLLMs, including the most advanced GPT-4V and Gemini-Pro-Vision.            
          </p>
        </div>
      </div>
    </div>
  </div>
  <!--/ Abstract. -->
</section>

<section class="section pipeline-section">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Pipeline</h2>
        <img src="static/images/fig2.jpg" width="960" height="660">
    </div>
  </div>
</section>
<section class="section experiment-section">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Experiments</h2>
        <img src="static/images/fig3.png" width="960" height="660">      
    </div>
  </div>
</section>


  </section>
<section class="section demos-section">
  <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Demos</h2>
                  <body>
    <video width="960" height="960" controls>
        <source src="static/images/demo1.mp4" type="video/mp4">
    </video>
    <h2 class="subtitle has-text-centered">
          <p>
            <b>Aesthetic description </b>
          </p>
        </h2>
</body>   

                          <body>
    <video width="960" height="960" controls>
        <source src="static/images/demo2.mp4" type="video/mp4">
    </video>
    <h2 class="subtitle has-text-centered">
          <p>
            <b>Aesthetic description </b>
          </p>
        </h2>
</body>
    </div>
      </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{AesExpert,
  title={AesExpert: Towards Multi-modality Foundation Model for Image Aesthetics Perception},
  author={Yipo Huang and Xiangfei Sheng and Zhichao Yang and Quan Yuan and Zhichao Duan and Pengfei Chen and Leida Li and Weisi Lin and Guangming Shi},
  journal={arXiv:2404.09624},
  year={2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
